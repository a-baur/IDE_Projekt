{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "########## CONFIGURATION ###########\n",
    "GRAPH_PATH = \"../out/graph.ttl\"\n",
    "\n",
    "EXTRA_PATH = \"../out/extra/\"  # temporary data output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': 'https://openalex.org/W3176618563',\n 'doi': 'https://doi.org/10.18653/v1/2021.acl-demo.17',\n 'title': 'REM: Efficient Semi-Automated Real-Time Moderation of Online Forums',\n 'display_name': 'REM: Efficient Semi-Automated Real-Time Moderation of Online Forums',\n 'publication_year': 2021,\n 'publication_date': '2021-08-01',\n 'ids': {'openalex': 'https://openalex.org/W3176618563',\n  'doi': 'https://doi.org/10.18653/v1/2021.acl-demo.17',\n  'mag': '3176618563'},\n 'host_venue': {'id': None,\n  'issn_l': None,\n  'issn': None,\n  'display_name': 'meeting of the association for computational linguistics',\n  'publisher': 'Association for Computational Linguistics',\n  'type': 'publisher',\n  'url': 'https://doi.org/10.18653/v1/2021.acl-demo.17',\n  'is_oa': True,\n  'version': 'publishedVersion',\n  'license': 'cc-by'},\n 'type': 'proceedings-article',\n 'open_access': {'is_oa': True,\n  'oa_status': 'hybrid',\n  'oa_url': 'https://aclanthology.org/2021.acl-demo.17.pdf'},\n 'authorships': [{'author_position': 'first',\n   'author': {'id': 'https://openalex.org/A2525626150',\n    'display_name': 'Jakob Smedegaard Andersen',\n    'orcid': None},\n   'institutions': [{'id': 'https://openalex.org/I70451448',\n     'display_name': 'Hamburg University of Applied Sciences',\n     'ror': 'https://ror.org/00fkqwx76',\n     'country_code': 'DE',\n     'type': 'education'}],\n   'raw_affiliation_string': None},\n  {'author_position': 'middle',\n   'author': {'id': 'https://openalex.org/A721429111',\n    'display_name': 'Olaf Zukunft',\n    'orcid': None},\n   'institutions': [{'id': 'https://openalex.org/I70451448',\n     'display_name': 'Hamburg University of Applied Sciences',\n     'ror': 'https://ror.org/00fkqwx76',\n     'country_code': 'DE',\n     'type': 'education'}],\n   'raw_affiliation_string': None},\n  {'author_position': 'last',\n   'author': {'id': 'https://openalex.org/A3186294417',\n    'display_name': 'Walid Maalej',\n    'orcid': None},\n   'institutions': [{'id': 'https://openalex.org/I159176309',\n     'display_name': 'Universit√§t Hamburg',\n     'ror': 'https://ror.org/00g30e956',\n     'country_code': 'DE',\n     'type': 'education'}],\n   'raw_affiliation_string': None}],\n 'cited_by_count': 0,\n 'biblio': {'volume': None,\n  'issue': None,\n  'first_page': '142',\n  'last_page': '149'},\n 'is_retracted': False,\n 'is_paratext': False,\n 'concepts': [{'id': 'https://openalex.org/C41008148',\n   'wikidata': 'https://www.wikidata.org/wiki/Q21198',\n   'display_name': 'Computer science',\n   'level': 0,\n   'score': '0.648933'},\n  {'id': 'https://openalex.org/C2986087404',\n   'wikidata': 'https://www.wikidata.org/wiki/Q15946010',\n   'display_name': 'Online learning',\n   'level': 2,\n   'score': '0.338109'},\n  {'id': 'https://openalex.org/C2779662365',\n   'wikidata': 'https://www.wikidata.org/wiki/Q5416694',\n   'display_name': 'Event (particle physics)',\n   'level': 2,\n   'score': '0.32608'}],\n 'mesh': [],\n 'alternate_host_venues': [{'id': None,\n   'display_name': None,\n   'type': 'journal',\n   'url': 'https://aclanthology.org/2021.acl-demo.17.pdf',\n   'is_oa': True,\n   'version': 'publishedVersion',\n   'license': 'cc-by'}],\n 'referenced_works': ['https://openalex.org/W1993613062',\n  'https://openalex.org/W2382312077',\n  'https://openalex.org/W2189465200',\n  'https://openalex.org/W2996500226',\n  'https://openalex.org/W2184059664',\n  'https://openalex.org/W2241850672',\n  'https://openalex.org/W2028138594',\n  'https://openalex.org/W2101807845',\n  'https://openalex.org/W2792592348',\n  'https://openalex.org/W2740895812',\n  'https://openalex.org/W2941394980',\n  'https://openalex.org/W2065010255',\n  'https://openalex.org/W2753079413',\n  'https://openalex.org/W2903158431',\n  'https://openalex.org/W3011542385',\n  'https://openalex.org/W2945828977',\n  'https://openalex.org/W2962855291',\n  'https://openalex.org/W2003238113',\n  'https://openalex.org/W2111189837',\n  'https://openalex.org/W2766005220',\n  'https://openalex.org/W2953384591',\n  'https://openalex.org/W2474803649',\n  'https://openalex.org/W2942161347',\n  'https://openalex.org/W1997326096',\n  'https://openalex.org/W2097749765'],\n 'related_works': ['https://openalex.org/W1567007040',\n  'https://openalex.org/W2501050832',\n  'https://openalex.org/W2410722524',\n  'https://openalex.org/W2991099293',\n  'https://openalex.org/W2342281051',\n  'https://openalex.org/W3088852692',\n  'https://openalex.org/W2754215704',\n  'https://openalex.org/W3168476095',\n  'https://openalex.org/W2527660037',\n  'https://openalex.org/W2805116311',\n  'https://openalex.org/W2979602389',\n  'https://openalex.org/W78250886',\n  'https://openalex.org/W2587467493',\n  'https://openalex.org/W279631868',\n  'https://openalex.org/W3023398882',\n  'https://openalex.org/W2166345396',\n  'https://openalex.org/W1855293664',\n  'https://openalex.org/W2783693948',\n  'https://openalex.org/W2791919974',\n  'https://openalex.org/W2511173823'],\n 'abstract_inverted_index': {'This': [0],\n  'paper': [1],\n  'presents': [2],\n  'REM,': [3],\n  'a': [4, 46, 66, 98, 111],\n  'novel': [5],\n  'tool': [6, 96],\n  'for': [7, 20, 83],\n  'the': [8, 24, 59, 73, 104, 117, 125],\n  'semi-automated': [9, 67],\n  'real-time': [10],\n  'moderation': [11, 48, 68],\n  'of': [12, 27, 62, 75, 106, 119, 128],\n  'large': [13],\n  'scale': [14, 51],\n  'online': [15, 21, 43, 107],\n  'forums.': [16, 44],\n  'The': [17],\n  'growing': [18],\n  'demand': [19],\n  'participation': [22],\n  'and': [23, 36, 53, 122],\n  'increasing': [25],\n  'number': [26],\n  'user': [28],\n  'comments': [29, 82],\n  'raise': [30],\n  'challenges': [31],\n  'in': [32, 42],\n  'filtering': [33],\n  'out': [34],\n  'harmful': [35],\n  'undesirable': [37],\n  'content': [38],\n  'from': [39],\n  'public': [40],\n  'debates': [41],\n  'Since': [45],\n  'manual': [47, 76],\n  'does': [49],\n  'not': [50],\n  'well': [52],\n  'pure': [54],\n  'automated': [55],\n  'approaches': [56],\n  'often': [57],\n  'lack': [58],\n  'required': [60],\n  'level': [61],\n  'accuracy,': [63],\n  'we': [64],\n  'suggest': [65],\n  'approach.': [69],\n  'Our': [70, 95],\n  'approach': [71, 121],\n  'maximizes': [72],\n  'efficiency': [74],\n  'efforts': [77],\n  'by': [78],\n  'targeting': [79],\n  'only': [80],\n  'those': [81],\n  'which': [84],\n  'human': [85],\n  'intervention': [86],\n  'is': [87],\n  'needed,': [88],\n  'e.g.': [89],\n  'due': [90],\n  'to': [91, 115],\n  'high': [92],\n  'classification': [93],\n  'uncertainty.': [94],\n  'offers': [97],\n  'rich': [99],\n  'visual': [100],\n  'interactive': [101],\n  'environment': [102],\n  'enabling': [103],\n  'exploration': [105],\n  'debates.': [108],\n  'We': [109],\n  'conduct': [110],\n  'preliminary': [112],\n  'evaluation': [113],\n  'experiment': [114],\n  'demonstrate': [116],\n  'suitability': [118],\n  'our': [120],\n  'publicly': [123],\n  'release': [124],\n  'source': [126],\n  'code': [127],\n  'REM.': [129]},\n 'cited_by_api_url': 'https://api.openalex.org/works?filter=cites:W3176618563',\n 'counts_by_year': [],\n 'updated_date': '2021-11-03',\n 'created_date': '2021-07-05'}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "\n",
    "data_works = []\n",
    "for filename in glob(\"..\\\\data_collection\\\\2_get_works_output\\\\*.json\"):\n",
    "    with open(filename, encoding=\"utf8\") as f:\n",
    "        data_works.extend(json.load(f))\n",
    "\n",
    "data_works[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                title  \\\n0   Word-Level Uncertainty Estimation for Black-Bo...   \n2   The Two Shades of Dubbing in Neural Machine Tr...   \n4   Exploring Amharic Sentiment Analysis from Soci...   \n10       Towards Visual Data Science - An Exploration   \n12  Evaluating the Scaling of Graph-Algorithms for...   \n\n                              type   venue  year  \\\n0   Conference and Workshop Papers  COLING  2020   \n2   Conference and Workshop Papers  COLING  2020   \n4   Conference and Workshop Papers  COLING  2020   \n10  Conference and Workshop Papers   IHIET  2019   \n12  Conference and Workshop Papers     OBD  2016   \n\n                                           url       city  country  \n0   https://dblp.org/db/conf/coling/index.html  Barcelona    Spain  \n2   https://dblp.org/db/conf/coling/index.html  Barcelona    Spain  \n4   https://dblp.org/db/conf/coling/index.html  Barcelona    Spain  \n10   https://dblp.org/db/conf/ihiet/index.html       Nice   France  \n12     https://dblp.org/db/conf/obd/index.html     Vienna  Austria  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>type</th>\n      <th>venue</th>\n      <th>year</th>\n      <th>url</th>\n      <th>city</th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Word-Level Uncertainty Estimation for Black-Bo...</td>\n      <td>Conference and Workshop Papers</td>\n      <td>COLING</td>\n      <td>2020</td>\n      <td>https://dblp.org/db/conf/coling/index.html</td>\n      <td>Barcelona</td>\n      <td>Spain</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Two Shades of Dubbing in Neural Machine Tr...</td>\n      <td>Conference and Workshop Papers</td>\n      <td>COLING</td>\n      <td>2020</td>\n      <td>https://dblp.org/db/conf/coling/index.html</td>\n      <td>Barcelona</td>\n      <td>Spain</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Exploring Amharic Sentiment Analysis from Soci...</td>\n      <td>Conference and Workshop Papers</td>\n      <td>COLING</td>\n      <td>2020</td>\n      <td>https://dblp.org/db/conf/coling/index.html</td>\n      <td>Barcelona</td>\n      <td>Spain</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Towards Visual Data Science - An Exploration</td>\n      <td>Conference and Workshop Papers</td>\n      <td>IHIET</td>\n      <td>2019</td>\n      <td>https://dblp.org/db/conf/ihiet/index.html</td>\n      <td>Nice</td>\n      <td>France</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Evaluating the Scaling of Graph-Algorithms for...</td>\n      <td>Conference and Workshop Papers</td>\n      <td>OBD</td>\n      <td>2016</td>\n      <td>https://dblp.org/db/conf/obd/index.html</td>\n      <td>Vienna</td>\n      <td>Austria</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "locations = []\n",
    "venues = []\n",
    "\n",
    "ven_files = glob(\"../data_collection/venues/*.json\")\n",
    "loc_files = glob(\"../data_collection/locations/*.json\")\n",
    "\n",
    "ven_dfs = []\n",
    "loc_dfs = []\n",
    "for fn_ven, fn_loc in zip(ven_files, loc_files):\n",
    "    with open(fn_ven) as f_ven, open(fn_loc) as f_loc:\n",
    "        loc_dfs.append(pd.read_json(f_loc, orient=\"records\"))\n",
    "        ven_dfs.append(pd.read_json(f_ven, orient=\"records\"))\n",
    "\n",
    "ven_df = pd.concat(ven_dfs, axis=0, ignore_index=True)\n",
    "loc_df = pd.concat(loc_dfs, axis=0, ignore_index=True)\n",
    "loc_df = loc_df.dropna(subset=[\"city\", \"country\"])\n",
    "\n",
    "str_cols = [\"title\", \"type\", \"venue\", \"url\"]\n",
    "ven_df[str_cols] = ven_df[str_cols].astype(str)\n",
    "\n",
    "str_cols = [\"city\", \"country\", \"venue\"]\n",
    "loc_df[str_cols] = loc_df[str_cols].astype(str)\n",
    "\n",
    "df = pd.merge(ven_df, loc_df, on=[\"venue\", \"year\"])\n",
    "df = df.drop_duplicates()\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pickle\n",
    "\n",
    "coord_fn = EXTRA_PATH + \"city_coords.pkl\"\n",
    "if os.path.isfile(coord_fn):\n",
    "    with open(coord_fn, 'rb') as f:\n",
    "        city_coords = pickle.load(f)\n",
    "else:\n",
    "    city_coords = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding work 0/4891 (0%)      \n",
      "Saving for iteration 0\n",
      "\n",
      "Adding work 200/4891 (4.1%)      \n",
      "Saving for iteration 200\n",
      "\n",
      "Adding work 400/4891 (8.2%)      \n",
      "Saving for iteration 400\n",
      "\n",
      "Adding work 600/4891 (12%)       \n",
      "Saving for iteration 600\n",
      "\n",
      "Adding work 800/4891 (16%)      \n",
      "Saving for iteration 800\n",
      "\n",
      "Adding work 1000/4891 (20%)      \n",
      "Saving for iteration 1000\n",
      "\n",
      "Adding work 1200/4891 (25%)      \n",
      "Saving for iteration 1200\n",
      "\n",
      "Adding work 1400/4891 (29%)      \n",
      "Saving for iteration 1400\n",
      "\n",
      "Adding work 1600/4891 (33%)      \n",
      "Saving for iteration 1600\n",
      "\n",
      "Adding work 1800/4891 (37%)      \n",
      "Saving for iteration 1800\n",
      "\n",
      "Adding work 2000/4891 (41%)      \n",
      "Saving for iteration 2000\n",
      "\n",
      "Adding work 2200/4891 (45%)      \n",
      "Saving for iteration 2200\n",
      "\n",
      "Adding work 2400/4891 (49%)      \n",
      "Saving for iteration 2400\n",
      "\n",
      "Adding work 2600/4891 (53%)      \n",
      "Saving for iteration 2600\n",
      "\n",
      "Adding work 2800/4891 (57%)      \n",
      "Saving for iteration 2800\n",
      "\n",
      "Adding work 3000/4891 (61%)      \n",
      "Saving for iteration 3000\n",
      "\n",
      "Adding work 3200/4891 (65%)      \n",
      "Saving for iteration 3200\n",
      "\n",
      "Adding work 3400/4891 (70%)      \n",
      "Saving for iteration 3400\n",
      "\n",
      "Adding work 3600/4891 (74%)      \n",
      "Saving for iteration 3600\n",
      "\n",
      "Adding work 3800/4891 (78%)      \n",
      "Saving for iteration 3800\n",
      "\n",
      "Adding work 4000/4891 (82%)      \n",
      "Saving for iteration 4000\n",
      "\n",
      "Adding work 4200/4891 (86%)      \n",
      "Saving for iteration 4200\n",
      "\n",
      "Adding work 4400/4891 (90%)      \n",
      "Saving for iteration 4400\n",
      "\n",
      "Adding work 4600/4891 (94%)      \n",
      "Saving for iteration 4600\n",
      "\n",
      "Adding work 4800/4891 (98%)      \n",
      "Saving for iteration 4800\n",
      "\n",
      "Adding work 4890/4891 (1e+02%)      "
     ]
    },
    {
     "data": {
      "text/plain": "<Graph identifier=N5289a4e85e114a349ae6394991c52742 (<class 'graph.oa_graph.OpenAlexGraph'>)>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.parse import quote_plus\n",
    "from graph.oa_graph_json import OpenAlexGraph, _resource_from_uri\n",
    "\n",
    "\n",
    "SAVE_AFTER_BATCH = 200\n",
    "\n",
    "\n",
    "def get_dbr_resource(term: str):\n",
    "    if not isinstance(term, str):\n",
    "        return\n",
    "    term = term.replace(' ', '_')\n",
    "    resource = quote_plus(term)\n",
    "    return resource\n",
    "\n",
    "\n",
    "def get_coord_from_dbo(city: str):\n",
    "    \"\"\"\n",
    "    Workaround for service queries in rdflib not working:\n",
    "    Request node uri and get coordinates.\n",
    "\n",
    "    :param city: City resource name\n",
    "    :return: lat, lng\n",
    "    \"\"\"\n",
    "    if not isinstance(city, str):\n",
    "        return None, None\n",
    "    if city in city_coords:\n",
    "        return city_coords[city]\n",
    "    uri = \"http://dbpedia.org/resource/\" + city\n",
    "    resp = requests.get(uri, headers={\"accept\": \"application/json\"})\n",
    "    try:\n",
    "        node = resp.json()[uri]\n",
    "        lng = node['http://www.w3.org/2003/01/geo/wgs84_pos#long'][0][\"value\"]\n",
    "        lat = node['http://www.w3.org/2003/01/geo/wgs84_pos#lat'][0][\"value\"]\n",
    "        city_coords[city] = (lat, lng)\n",
    "        return lat, lng\n",
    "    except KeyError:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "g = OpenAlexGraph()\n",
    "\n",
    "total = len(data_works)\n",
    "for i, item in enumerate(data_works):\n",
    "    print(\n",
    "        f\"\\rAdding work {i}/{total} ({i/total * 100:.2g}%)      \",\n",
    "        end=\"\"\n",
    "    )\n",
    "    host_venue = item[\"host_venue\"]\n",
    "    host_id = _resource_from_uri(host_venue[\"id\"])\n",
    "\n",
    "    # Add work\n",
    "    work_id = _resource_from_uri(item[\"id\"])\n",
    "    work_name = item[\"display_name\"]\n",
    "    g.add_work(\n",
    "        identifier=work_id,\n",
    "        name=work_name,\n",
    "        date_published=item[\"publication_date\"],\n",
    "    )\n",
    "\n",
    "    for cites_by_year in item[\"counts_by_year\"]:\n",
    "        g.add_citations_in_year(\n",
    "            identifier=work_id,\n",
    "            year=cites_by_year[\"year\"],\n",
    "            citations=cites_by_year[\"cited_by_count\"]\n",
    "        )\n",
    "\n",
    "    # Add authors of paper and is_author relation\n",
    "    prev_author = None\n",
    "    for authorship in item[\"authorships\"]:\n",
    "        author = authorship[\"author\"]\n",
    "        author_id = _resource_from_uri(author[\"id\"])\n",
    "        author_name = author[\"display_name\"]\n",
    "\n",
    "        inst_id = None\n",
    "        if authorship[\"institutions\"]:\n",
    "            inst = authorship[\"institutions\"][0]\n",
    "            inst_id = _resource_from_uri(inst[\"id\"])\n",
    "            inst_name = inst[\"display_name\"]\n",
    "            g.add_institution(inst_id, inst_name)\n",
    "            g.add_associated_with_institution(work_id, inst_id)\n",
    "\n",
    "        g.add_author(author_id, author_name, inst_id)\n",
    "        if prev_author:\n",
    "            g.add_colleague(author_id, prev_author)\n",
    "        prev_author = author_id\n",
    "        g.add_is_author(author_id, work_id)\n",
    "\n",
    "    ven = df[df[\"title\"] == work_name]\n",
    "    if not ven.empty:\n",
    "        ven = ven.iloc[0]\n",
    "        ven_id = _resource_from_uri(ven[\"url\"], res_loc=-2)\n",
    "        ven_city = get_dbr_resource(ven[\"city\"])\n",
    "        ven_country = get_dbr_resource(ven[\"country\"])\n",
    "        lat, lng = get_coord_from_dbo(ven_city)  # workaround for SERVICE not working\n",
    "        g.add_venue(\n",
    "            work_id=work_id,\n",
    "            identifier=ven_id,\n",
    "            name=ven[\"venue\"],\n",
    "            year=ven[\"year\"],\n",
    "            city=ven_city,\n",
    "            country=ven_country,\n",
    "            lat=lat,\n",
    "            lng=lng,\n",
    "\n",
    "        )\n",
    "\n",
    "    if i % SAVE_AFTER_BATCH == 0:\n",
    "        print(f\"\\nSaving for iteration {i}\\n\")\n",
    "        g.serialize(GRAPH_PATH)\n",
    "\n",
    "g.serialize(GRAPH_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding 1755 institutions\n",
      "\n",
      "Adding location for institution, no. 0\n",
      "Saving for iteration 0\n",
      "\n",
      "Adding location for institution, no. 50\n",
      "Saving for iteration 50\n",
      "\n",
      "Adding location for institution, no. 250\n",
      "Saving for iteration 250\n",
      "\n",
      "Adding location for institution, no. 300\n",
      "Saving for iteration 300\n",
      "\n",
      "Adding location for institution, no. 350\n",
      "Saving for iteration 350\n",
      "\n",
      "Adding location for institution, no. 400\n",
      "Saving for iteration 400\n",
      "\n",
      "Adding location for institution, no. 650\n",
      "Saving for iteration 650\n",
      "\n",
      "Adding location for institution, no. 850\n",
      "Saving for iteration 850\n",
      "\n",
      "Adding location for institution, no. 900\n",
      "Saving for iteration 900\n",
      "\n",
      "Adding location for institution, no. 950\n",
      "Saving for iteration 950\n",
      "\n",
      "Adding location for institution, no. 1050\n",
      "Saving for iteration 1050\n",
      "\n",
      "Adding location for institution, no. 1200\n",
      "Saving for iteration 1200\n",
      "\n",
      "Adding location for institution, no. 1400\n",
      "Saving for iteration 1400\n",
      "\n",
      "Adding location for institution, no. 1450\n",
      "Saving for iteration 1450\n",
      "\n",
      "Adding location for institution, no. 1500\n",
      "Saving for iteration 1500\n",
      "\n",
      "Adding location for institution, no. 1754"
     ]
    },
    {
     "data": {
      "text/plain": "<Graph identifier=N5289a4e85e114a349ae6394991c52742 (<class 'graph.oa_graph.OpenAlexGraph'>)>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graph.oa_request import oa_request\n",
    "\n",
    "\n",
    "SAVE_AFTER_BATCH = 50\n",
    "\n",
    "\n",
    "def get_dbr_uri(term: str):\n",
    "    if not term:\n",
    "        return\n",
    "    term = term.replace(' ', '_')\n",
    "    resource = quote_plus(term)\n",
    "    return \"https://dbpedia.org/resource/\" + resource\n",
    "\n",
    "\n",
    "def get_institutions(g):\n",
    "    q = \"\"\"\n",
    "        SELECT DISTINCT ?inst_id\n",
    "        WHERE {\n",
    "            ?inst_id a schema:EducationalOrganization .\n",
    "            FILTER NOT EXISTS {\n",
    "              ?inst_id schema:location ?x\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    q_res = g.query(q)\n",
    "    result = []\n",
    "    for row in q_res:\n",
    "        result.append(row.inst_id)\n",
    "    return result\n",
    "\n",
    "\n",
    "institutions = get_institutions(g)\n",
    "print(f\"adding {len(institutions)} institutions\\n\")\n",
    "for i, inst in enumerate(institutions):\n",
    "    print(f\"\\rAdding location for institution, no. {i}\", end=\"\")\n",
    "    inst_id = _resource_from_uri(inst)\n",
    "    if inst_id.startswith(\"_\"):\n",
    "        continue\n",
    "    _filter = {\"openalex_id\": str(inst)}\n",
    "    loc = oa_request(\"institutions\", _filter)[0][\"geo\"]\n",
    "    dbo_country = get_dbr_uri(loc[\"country\"])\n",
    "    dbo_city = get_dbr_uri(loc[\"city\"])\n",
    "    g.add_located_at(\n",
    "        identifier=inst_id,\n",
    "        country=_resource_from_uri(dbo_country),\n",
    "        city=_resource_from_uri(dbo_city),\n",
    "        latitude=loc[\"latitude\"],\n",
    "        longitude=loc[\"longitude\"]\n",
    "    )\n",
    "    if i % SAVE_AFTER_BATCH == 0:\n",
    "        print(f\"\\nSaving for iteration {i}\\n\")\n",
    "        g.serialize(GRAPH_PATH)\n",
    "\n",
    "g.serialize(GRAPH_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "115139"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "with open(\"../out/city_coords.pkl\", 'wb') as f:\n",
    "    pickle.dump(city_coords, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}